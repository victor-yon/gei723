{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEI723, Université de Sherbrooke, Oct. 2020. Jean Rouat\n",
    "\n",
    "Ce notebook est une adaptation de la classification par STDP de MNIST par Diehl & Cook, créé par I. Balafrej pour l'automne 2019, et adapté par A. El Ferdaoussi pour l'automne 2020.\n",
    "\n",
    "L'article de Diehl & Cook est disponible ici: https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full\n",
    "\n",
    "Le modèle est simplifié un peu et réécrit pour Brian2 et Python 3. Le code est à trous, et les parties à compléter sont indiquées par 'COMPLETER'.\n",
    "\n",
    "ATTENTION: 'exemple donné ici utilise seulement des données d'entrainement et de validation (appelées à tort \"test\").\n",
    "\n",
    "Les équations et certains paramètres des neurones sont fournies.\n",
    "\n",
    "Un exemple d'encodage par fréquence est utilisé (voir la partie \"testons à présent le réseau entrainé'). Vous avez toute liberté d'utiliser un autre type d'encodage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_LIMIT = 100\n",
    "TEST_SIZE = 50\n",
    "NUMBER_NODES_PER_LAYER = 100\n",
    "NORMALIZATION = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de données MNIST\n",
    "\n",
    "On télécharge l'ensemble de données MNIST directement dans le code. MNIST est disponible à https://www.openml.org/d/554\n",
    "\n",
    "L'argument 'data_home' peut être utilisé pour télécharger MNIST dans un répertoire de votre choix. (Le répertoire par défaut est '~/scikit_learn_data/'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-114-1a2832bfc4b1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mX_all\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_all\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch_openml\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'mnist_784'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mversion\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_X_y\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_home\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'./data'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     70\u001B[0m                           FutureWarning)\n\u001B[1;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36mfetch_openml\u001B[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)\u001B[0m\n\u001B[1;32m    814\u001B[0m     \u001B[0;31m# obtain the data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    815\u001B[0m     \u001B[0murl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_DATA_FILE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_description\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'file_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 816\u001B[0;31m     bunch = _download_data_to_bunch(url, return_sparse, data_home,\n\u001B[0m\u001B[1;32m    817\u001B[0m                                     \u001B[0mas_frame\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_frame\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m                                     \u001B[0mfeatures_list\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfeatures_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36m_download_data_to_bunch\u001B[0;34m(url, sparse, data_home, as_frame, features_list, data_columns, target_columns, shape)\u001B[0m\n\u001B[1;32m    555\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnominal_attributes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m     out = _retry_with_clean_cache(url, data_home)(\n\u001B[0m\u001B[1;32m    558\u001B[0m         \u001B[0m_load_arff_response\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_home\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m                              \u001B[0mreturn_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_type\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m     51\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36m_load_arff_response\u001B[0;34m(url, data_home, return_type, encode_nominal, parse_arff)\u001B[0m\n\u001B[1;32m    464\u001B[0m                           \u001B[0mreturn_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_type\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    465\u001B[0m                           encode_nominal=encode_nominal)\n\u001B[0;32m--> 466\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mparse_arff\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marff\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    467\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36mparse_arff\u001B[0;34m(arff)\u001B[0m\n\u001B[1;32m    519\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mparse_arff\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marff\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 521\u001B[0;31m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_convert_arff_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marff\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol_slice_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol_slice_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    522\u001B[0m             \u001B[0;31m# nominal attributes is a dict mapping from the attribute name to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0;31m# the possible values. Includes also the target column (which will\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py\u001B[0m in \u001B[0;36m_convert_arff_data\u001B[0;34m(arff, col_slice_x, col_slice_y, shape)\u001B[0m\n\u001B[1;32m    250\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m             \u001B[0mcount\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m         data = np.fromiter(itertools.chain.from_iterable(arff_data),\n\u001B[0m\u001B[1;32m    253\u001B[0m                            dtype='float64', count=count)\n\u001B[1;32m    254\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/externals/_arff.py\u001B[0m in \u001B[0;36mdecode_rows\u001B[0;34m(self, stream, conversors)\u001B[0m\n\u001B[1;32m    459\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdecode_rows\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconversors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    460\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 461\u001B[0;31m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_parse_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    462\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    463\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/data/Workplace/gei723/venv/lib/python3.8/site-packages/sklearn/externals/_arff.py\u001B[0m in \u001B[0;36m_parse_values\u001B[0;34m(s)\u001B[0m\n\u001B[1;32m    272\u001B[0m         \u001B[0;31m# values because of the empty string case :(.)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m         return [None if s in ('?', '') else s\n\u001B[0;32m--> 274\u001B[0;31m                 for s in next(csv.reader([s]))]\n\u001B[0m\u001B[1;32m    275\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[0;31m# _RE_DENSE_VALUES tokenizes despite quoting, whitespace, etc.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "X_all, y_all = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST est constituté de 70k d'images de 28x28 pixels, de chiffres.\n",
    "\n",
    "'X' est le vecteur d'images, et 'y' est le vecteur d'étiquettes (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulation avec toutes les images est assez longue à faire rouler. Utilisons uniquement un sous-ensemble de MNIST pour une simulation plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all[:DATA_LIMIT] # Completed\n",
    "y = y_all[:DATA_LIMIT] # Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisons MNIST en ensembles d'entrainement et de test pour entrainer et tester le modèle post-apprentissage.\n",
    "\n",
    "Si on travaille avec l'ensemble au complet, on peut prendre 10k pour le test par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=TEST_SIZE) # Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons une image aléatoire de l'ensemble de données pour voir ce à quoi ressemble MNIST.\n",
    "\n",
    "Les images dans MNIST sont des vecteurs. Il faut donc les ré-organiser en matrice 28x28 pour les afficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(X_train)-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Échantillon MNIST avec étiquette %s\" % y_train[index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones Brian2\n",
    "\n",
    "On peut maintenant créer un réseau Brian2. Commençons par définir quelques paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixons le seed aléatoire afin de pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "\n",
    "# Horloge de Brian2\n",
    "defaultclock.dt = 0.5 * units.ms\n",
    "\n",
    "# Cible de génération de code pour Brian2\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "time_per_sample =   0.35 * units.second\n",
    "resting_time = 0.15 * units.second\n",
    "\n",
    "v_rest_e = -65. * units.mV \n",
    "v_rest_i = -60. * units.mV \n",
    "\n",
    "v_reset_e = -65. * units.mV\n",
    "v_reset_i = -45. * units.mV\n",
    "\n",
    "v_thresh_e = -52. * units.mV\n",
    "v_thresh_i = -40. * units.mV\n",
    "\n",
    "refrac_e = 5. * units.ms\n",
    "refrac_i = 2. * units.ms\n",
    "\n",
    "tc_theta = 1e7 * units.ms\n",
    "theta_plus_e = 0.05 * units.mV\n",
    "\n",
    "tc_pre_ee = 20 * units.ms\n",
    "tc_post_1_ee = 20 * units.ms\n",
    "tc_post_2_ee = 40 * units.ms\n",
    "\n",
    "# Taux d'apprentissage\n",
    "nu_ee_pre =  0.1 # [0, 1] Completed\n",
    "nu_ee_post = 0.1 # [0, 1] Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons l'entrée au réseau de neurones. L'entrée est un encodeur de type codage par fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rates = np.ones([1,784])  # Completed\n",
    "input_group = PoissonGroup(784, rates = input_rates*Hz) # Groupe de Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons notre modèle de neurone ainsi que nos groupes de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_model = '''\n",
    "    dv/dt = ((v_rest_e - v) + (I_synE + I_synI) / nS) / tau  : volt (unless refractory)\n",
    "\n",
    "    I_synE =  ge * nS * -v           : amp\n",
    "    \n",
    "    I_synI =  gi * nS * (d_I_synI-v) : amp\n",
    "    \n",
    "    dge/dt = -ge/(1.0*ms)            : 1\n",
    "    \n",
    "    dgi/dt = -gi/(2.0*ms)            : 1\n",
    "    \n",
    "    tau                              : second (constant, shared)\n",
    "    \n",
    "    d_I_synI                         : volt (constant, shared)\n",
    "    \n",
    "    dtheta/dt = -theta / (tc_theta)  : volt\n",
    "'''\n",
    "# Completed\n",
    "excitatory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_e', \n",
    "    threshold='v > v_thresh_e + theta', reset='v = v_reset_e; theta += theta_plus_e', method='euler')\n",
    "excitatory_group.tau = 100 * units.ms\n",
    "excitatory_group.d_I_synI = -100. * units.mV\n",
    "\n",
    "# Completed\n",
    "inhibitory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_i', \n",
    "    threshold='v > v_thresh_i', reset='v = v_reset_i', method='euler')\n",
    "inhibitory_group.tau = 10 * units.ms\n",
    "inhibitory_group.d_I_synI = -85. * mV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_model = \"w : 1\"\n",
    "\n",
    "synapse_on_pre_i = \"ge_post -= w\"\n",
    "\n",
    "synapse_on_pre_e = \"gi_post += w\" # TODO check\n",
    "\n",
    "# Completed\n",
    "stdp_synapse_model = '''\n",
    "    w : 1\n",
    "\n",
    "    plastic : boolean (shared) # Activer/désactiver la plasticité\n",
    "    \n",
    "    post2before : 1  # x_tar ?\n",
    "\n",
    "    dpre/dt    = -pre/(tc_pre_ee) : 1 (event-driven)\n",
    "\n",
    "    dpost1/dt  = -post1/(tc_post_1_ee) : 1 (event-driven)\n",
    "\n",
    "    dpost2/dt  = -post2/(tc_post_2_ee) : 1 (event-driven)  # (?)\n",
    "\n",
    "    wmax = 10 : 1  # Completed\n",
    "\n",
    "    mu = 1 : 1  # Completed\n",
    "'''\n",
    "\n",
    "# Completed\n",
    "stdp_pre = '''\n",
    "    ge_post += w\n",
    "    \n",
    "    pre = 1.\n",
    "    \n",
    "    w = clip(w + (nu_ee_pre * post1), 0, wmax)\n",
    "'''\n",
    "\n",
    "# Completed\n",
    "# w = clip(w + nu_ee_post*(pre-post2before)*(wmax - w)**mu, 0, wmax)\n",
    "stdp_post = '''\n",
    "    post2before = post2\n",
    "    \n",
    "    w = clip(w + (nu_ee_post * pre), 0, wmax)\n",
    "    \n",
    "    post1 = -1.\n",
    "\n",
    "    post2 = 1.\n",
    "'''\n",
    "\n",
    "input_synapse = Synapses(input_group, excitatory_group, model=stdp_synapse_model, on_pre=stdp_pre, on_post=stdp_post,\n",
    "                         method='euler') # Completed\n",
    "input_synapse.connect(True) # Fully connected\n",
    "input_synapse.delay = '10 * ms' # Completed\n",
    "input_synapse.plastic = True\n",
    "# input_synapse.w = 'rand()*10' # Completed\n",
    "input_synapse.w = '5' # Completed\n",
    "\n",
    "e_i_synapse = Synapses(excitatory_group, inhibitory_group, model=synapse_model, method='euler') # Completed\n",
    "e_i_synapse.connect(True, p=0.0025)\n",
    "e_i_synapse.w = 'rand()*10.4'\n",
    "\n",
    "i_e_synapse = Synapses(inhibitory_group, excitatory_group, model=synapse_model, method='euler') # Completed\n",
    "i_e_synapse.connect(True, p=0.9)\n",
    "i_e_synapse.w = 'rand()*17.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de synapses a-t-on dans le réseau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(input_synapse) + len(e_i_synapse) + len(i_e_synapse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons un 'readout' pour notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_monitor = SpikeMonitor(excitatory_group, record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(input_group, excitatory_group, inhibitory_group, \n",
    "              input_synapse, e_i_synapse, i_e_synapse, e_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "Entrainons à présent notre réseau.\n",
    "\n",
    "Créons une matrice 'spikes' pour assigner les étiquettes des classes post-apprentissage. Cette matrice accumulera le décompte de décharges par classe.\n",
    "\n",
    "Notre readout 'e_monitor' est actif tout le long de la simulation avec toutes les images. Donc à chaque nouvelle présentation d'image, on doit soustraire l'ancien décompte de décharges. On utilisera le vecteur 'old_spike_counts' pour le faire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes = np.zeros((10, len(excitatory_group)))\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n",
    "\n",
    "# Entrainement\n",
    "number_of_epochs = 1\n",
    "\n",
    "for i in range(number_of_epochs):\n",
    "    print('Starting epoch %i' % i)\n",
    "    for j, (sample, label) in enumerate(zip(X_train, y_train)):\n",
    "        # Afficher régulièrement l'état d'avancement\n",
    "        if (j % 1) == 0:\n",
    "            print(\"Running sample %i out of %i\" % (j, len(X_train)))\n",
    "\n",
    "        # Configurer le taux d'entrée\n",
    "        input_group.rates = sample / 4 * units.Hz # Completed\n",
    "\n",
    "        # Simuler le réseau\n",
    "        net.run(time_per_sample)\n",
    "\n",
    "        # Enregistrer les décharges\n",
    "        spikes[int(label)] += e_monitor.count - old_spike_counts\n",
    "        # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "        \n",
    "\n",
    "        weight_matrix = np.zeros([784, NUMBER_NODES_PER_LAYER]) # Completed\n",
    "        weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "        print(f'Weights avg: {np.average(weight_matrix)}')\n",
    "        print('-------------- Matrix - 0:10 --------------')\n",
    "        print(weight_matrix[0:10,0:10])\n",
    "        print('-------------- Matrix - 385:395 --------------')\n",
    "        print('input')\n",
    "        print(input_group.rates[385:395])\n",
    "        print('matrix')\n",
    "        print(weight_matrix[385:395,0:10])\n",
    "\n",
    "        # Arrêter l'entrée\n",
    "        input_group.rates = 0 * units.Hz\n",
    "        \n",
    "        # Laisser les variables retourner à leurs valeurs de repos\n",
    "        net.run(resting_time)\n",
    "\n",
    "        # Normaliser les poids\n",
    "        if NORMALIZATION:\n",
    "\n",
    "            weight_matrix = np.zeros([784, NUMBER_NODES_PER_LAYER]) # Completed\n",
    "            weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "            # weight_matrix = weight_matrix/input_synapse.wmax\n",
    "            # colFactors = weight_matrix[0] / col_sums\n",
    "            col_sums = np.sum(weight_matrix, axis=0) # Completed\n",
    "            colFactors = 1 / col_sums # Completed\n",
    "\n",
    "            for k in range(len(excitatory_group)):\n",
    "                weight_matrix[:,k] *= colFactors[k]\n",
    "            input_synapse.w = weight_matrix[input_synapse.i, input_synapse.j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Commençons par trouver le meilleur neurone pour chaque classe de MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_neurons = [[],[],[],[],[],[],[],[],[],[]] #liste pour chaque classe des indices des neurones qui ont déchargé le plus pour elle pendnat l'entrainement\n",
    "\n",
    "for i in range(len(excitatory_group)):\n",
    "    labeled_neurons[np.argmax(spikes[:,i])].append(spikes[np.argmax(spikes[:,i]),i])\n",
    "\n",
    "print(spikes)\n",
    "print(labeled_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent le réseau entrainé!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déasctiver la plasticité STDP\n",
    "input_synapse.plastic = False\n",
    "\n",
    "num_correct_output = 0\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(X_test, y_test)):\n",
    "    # Afficher régulièrement l'état d'avancement\n",
    "    if (i % 10) == 0:\n",
    "        print(\"Running sample %i out of %i\" % (i, len(X_test)))\n",
    "    \n",
    "    # Configurer le taux d'entrée\n",
    "    # ATTENTION, vous pouvez utiliser un autre type d'encodage\n",
    "    input_group.rates = sample / 4 * units.Hz # Completed\n",
    "    \n",
    "    # Simuler le réseau\n",
    "    net.run(time_per_sample)\n",
    "    \n",
    "    # Calculer le nombre de décharges pour l'échantillon\n",
    "    current_spike_count = e_monitor.count - old_spike_counts\n",
    "    # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "    old_spike_counts = np.copy(e_monitor.count)\n",
    "    \n",
    "    # Prédire la classe de l'échantillon\n",
    "    # Completed\n",
    "    #On récupére la moyenne des spikes des neurones correspondant aux classes\n",
    "    average = np.zeros(10)\n",
    "    for j in range(10):\n",
    "        neurone_interet = np.array([current_spike_count[x] for x in labeled_neurons[j]])\n",
    "        average[j] = mean(neurone_interet)\n",
    "\n",
    "    #On trouve le label (égal à l'indice de la plus grosse moyenne)\n",
    "    output_label = np.argmax(average)\n",
    "    #output_label = np.where(labeled_neurons == np.argmax(current_spike_count))[0][0]\n",
    "\n",
    "    # Si la prédiction est correcte\n",
    "    if output_label == int(label):\n",
    "        num_correct_output += 1\n",
    "        \n",
    "    # Laisser les variables retourner à leurs valeurs de repos\n",
    "    net.run(resting_time)\n",
    "\n",
    "    \n",
    "print(\"The model accuracy is : %.3f\" % (num_correct_output / len(X_test)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}