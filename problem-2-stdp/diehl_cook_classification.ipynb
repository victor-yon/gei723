{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEI723, Université de Sherbrooke, Oct. 2020. Jean Rouat\n",
    "\n",
    "Ce notebook est une adaptation de la classification par STDP de MNIST par Diehl & Cook, créé par I. Balafrej pour l'automne 2019, et adapté par A. El Ferdaoussi pour l'automne 2020.\n",
    "\n",
    "L'article de Diehl & Cook est disponible ici: https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full\n",
    "\n",
    "Le modèle est simplifié un peu et réécrit pour Brian2 et Python 3. Le code est à trous, et les parties à compléter sont indiquées par 'COMPLETER'.\n",
    "\n",
    "ATTENTION: 'exemple donné ici utilise seulement des données d'entrainement et de validation (appelées à tort \"test\").\n",
    "\n",
    "Les équations et certains paramètres des neurones sont fournies.\n",
    "\n",
    "Un exemple d'encodage par fréquence est utilisé (voir la partie \"testons à présent le réseau entrainé'). Vous avez toute liberté d'utiliser un autre type d'encodage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       Cache size for target \"cython\": 3929 MB.\n",
      "You can call \"clear_cache('cython')\" to delete all files from the cache or manually delete files in the \"C:\\Users\\solin\\.cython\\brian_extensions\" directory. [brian2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_LIMIT = 200\n",
    "TEST_SIZE = 50\n",
    "NUMBER_NODES_PER_LAYER = 100\n",
    "NORMALIZATION = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de données MNIST\n",
    "\n",
    "On télécharge l'ensemble de données MNIST directement dans le code. MNIST est disponible à https://www.openml.org/d/554\n",
    "\n",
    "L'argument 'data_home' peut être utilisé pour télécharger MNIST dans un répertoire de votre choix. (Le répertoire par défaut est '~/scikit_learn_data/'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST est constituté de 70k d'images de 28x28 pixels, de chiffres.\n",
    "\n",
    "'X' est le vecteur d'images, et 'y' est le vecteur d'étiquettes (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulation avec toutes les images est assez longue à faire rouler. Utilisons uniquement un sous-ensemble de MNIST pour une simulation plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LIMIT = 200\n",
    "TEST_SIZE = 50\n",
    "X = X_all[:DATA_LIMIT] # Completed\n",
    "y = y_all[:DATA_LIMIT] # Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisons MNIST en ensembles d'entrainement et de test pour entrainer et tester le modèle post-apprentissage.\n",
    "\n",
    "Si on travaille avec l'ensemble au complet, on peut prendre 10k pour le test par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=TEST_SIZE) # Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons une image aléatoire de l'ensemble de données pour voir ce à quoi ressemble MNIST.\n",
    "\n",
    "Les images dans MNIST sont des vecteurs. Il faut donc les ré-organiser en matrice 28x28 pour les afficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(X_train)-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Échantillon MNIST avec étiquette %s\" % y_train[index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones Brian2\n",
    "\n",
    "On peut maintenant créer un réseau Brian2. Commençons par définir quelques paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixons le seed aléatoire afin de pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "\n",
    "# Horloge de Brian2\n",
    "defaultclock.dt = 0.5 * units.ms\n",
    "\n",
    "# Cible de génération de code pour Brian2\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "time_per_sample =   0.35 * units.second\n",
    "resting_time = 0.15 * units.second\n",
    "\n",
    "v_rest_e = -65. * units.mV \n",
    "v_rest_i = -60. * units.mV \n",
    "\n",
    "v_reset_e = -65. * units.mV\n",
    "v_reset_i = -45. * units.mV\n",
    "\n",
    "v_thresh_e = -52. * units.mV\n",
    "v_thresh_i = -40. * units.mV\n",
    "\n",
    "refrac_e = 5. * units.ms\n",
    "refrac_i = 2. * units.ms\n",
    "\n",
    "tc_theta = 1e7 * units.ms\n",
    "theta_plus_e = 0.05 * units.mV\n",
    "\n",
    "tc_pre_ee = 20 * units.ms\n",
    "tc_post_1_ee = 20 * units.ms\n",
    "tc_post_2_ee = 40 * units.ms\n",
    "\n",
    "# Taux d'apprentissage\n",
    "nu_ee_pre =  0.5 # [0, 1] Completed\n",
    "nu_ee_post = 0.5 # [0, 1] Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons l'entrée au réseau de neurones. L'entrée est un encodeur de type codage par fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rates = np.ones([1,784])  # Completed\n",
    "input_group = PoissonGroup(784, rates = input_rates*Hz) # Groupe de Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons notre modèle de neurone ainsi que nos groupes de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_model = '''\n",
    "    dv/dt = ((v_rest_e - v) + (I_synE + I_synI) / nS) / tau  : volt (unless refractory)\n",
    "\n",
    "    I_synE =  ge * nS * -v           : amp\n",
    "    \n",
    "    I_synI =  gi * nS * (d_I_synI-v) : amp\n",
    "    \n",
    "    dge/dt = -ge/(1.0*ms)            : 1\n",
    "    \n",
    "    dgi/dt = -gi/(2.0*ms)            : 1\n",
    "    \n",
    "    tau                              : second (constant, shared)\n",
    "    \n",
    "    d_I_synI                         : volt (constant, shared)\n",
    "    \n",
    "    dtheta/dt = -theta / (tc_theta)  : volt\n",
    "'''\n",
    "# Completed\n",
    "excitatory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_e', \n",
    "    threshold='v > v_thresh_e + theta', reset='v = v_reset_e; theta += theta_plus_e', method='euler')\n",
    "excitatory_group.tau = 100 * units.ms\n",
    "excitatory_group.d_I_synI = -100. * units.mV\n",
    "\n",
    "# Completed\n",
    "inhibitory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_i', \n",
    "    threshold='v > v_thresh_i', reset='v = v_reset_i', method='euler')\n",
    "inhibitory_group.tau = 10 * units.ms\n",
    "inhibitory_group.d_I_synI = -85. * mV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_model = \"w : 1\"\n",
    "\n",
    "synapse_on_pre_i = \"ge_post -= w\"\n",
    "\n",
    "synapse_on_pre_e = \"gi_post += w\" # TODO check\n",
    "\n",
    "# Completed\n",
    "stdp_synapse_model = '''\n",
    "    w : 1\n",
    "\n",
    "    plastic : boolean (shared) # Activer/désactiver la plasticité\n",
    "    \n",
    "    post2before : 1  # x_tar ?\n",
    "\n",
    "    dpre/dt    = -pre/(tc_pre_ee) : 1 (event-driven)\n",
    "\n",
    "    dpost1/dt  = -post1/(tc_post_1_ee) : 1 (event-driven)\n",
    "\n",
    "    dpost2/dt  = -post2/(tc_post_2_ee) : 1 (event-driven)  # (?)\n",
    "\n",
    "    wmax = 10 : 1  # Completed\n",
    "\n",
    "    mu = 1 : 1  # Completed\n",
    "'''\n",
    "\n",
    "# Completed\n",
    "stdp_pre = '''\n",
    "    ge_post += w\n",
    "    \n",
    "    pre = 1.\n",
    "    \n",
    "    w = clip(w + (nu_ee_pre * post1), 0, wmax)\n",
    "'''\n",
    "\n",
    "# Completed\n",
    "# w = clip(w + nu_ee_post*(pre-post2before)*(wmax - w)**mu, 0, wmax)\n",
    "stdp_post = '''\n",
    "    post2before = post2\n",
    "    \n",
    "    w = clip(w + (nu_ee_post * pre), 0, wmax)\n",
    "    \n",
    "    post1 = -1.\n",
    "\n",
    "    post2 = 1.\n",
    "'''\n",
    "\n",
    "input_synapse = Synapses(input_group, excitatory_group, model=stdp_synapse_model, on_pre=stdp_pre, on_post=stdp_post,\n",
    "                         method='euler') # Completed\n",
    "input_synapse.connect(True, p= 1) # Fully connected\n",
    "input_synapse.delay = '10 * ms' # Completed\n",
    "input_synapse.plastic = True\n",
    "# input_synapse.w = 'rand()*10' # Completed\n",
    "input_synapse.w = '5' # Completed\n",
    "\n",
    "e_i_synapse = Synapses(excitatory_group, inhibitory_group, model=synapse_model, method='euler') # Completed\n",
    "e_i_synapse.connect(condition='i!=j')\n",
    "e_i_synapse.w = 'rand()*10.4'\n",
    "\n",
    "i_e_synapse = Synapses(inhibitory_group, excitatory_group, model=synapse_model, method='euler') # Completed\n",
    "i_e_synapse.connect(True, p=0.9)\n",
    "i_e_synapse.w = 'rand()*17.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de synapses a-t-on dans le réseau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97285\n"
     ]
    }
   ],
   "source": [
    "print(len(input_synapse) + len(e_i_synapse) + len(i_e_synapse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons un 'readout' pour notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_monitor = SpikeMonitor(excitatory_group, record=False)\n",
    "i_monitor = SpikeMonitor(inhibitory_group, record=False)\n",
    "#print(e_monitor.count)\n",
    "#print(\"taille\",  len(e_monitor.count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(input_group, excitatory_group, inhibitory_group, \n",
    "              input_synapse, e_i_synapse, i_e_synapse, e_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "Entrainons à présent notre réseau.\n",
    "\n",
    "Créons une matrice 'spikes' pour assigner les étiquettes des classes post-apprentissage. Cette matrice accumulera le décompte de décharges par classe.\n",
    "\n",
    "Notre readout 'e_monitor' est actif tout le long de la simulation avec toutes les images. Donc à chaque nouvelle présentation d'image, on doit soustraire l'ancien décompte de décharges. On utilisera le vecteur 'old_spike_counts' pour le faire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Running sample 0 out of 150\n",
      "matrix des poids centré\n",
      "[[5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]]\n",
      "Running sample 1 out of 150\n",
      "matrix des poids centré\n",
      "[[5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]]\n",
      "Running sample 2 out of 150\n",
      "matrix des poids centré\n",
      "[[ 9.91160315  9.91160315  9.91160315  9.91160315  9.91160315  9.91160315\n",
      "   9.91160315  9.91160315  9.91160315  9.91160315]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 3 out of 150\n",
      "matrix des poids centré\n",
      "[[10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]]\n",
      "Running sample 4 out of 150\n",
      "matrix des poids centré\n",
      "[[10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]]\n",
      "Running sample 5 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.89279268  8.89279268  8.89279268  8.89279268  8.89279268  8.89279268\n",
      "   8.89279268  8.89279268  8.89279268  8.89279268]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 6 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 7 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 8 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 9 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 10 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 11 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 12 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 13 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 14 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 15 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n",
      "Running sample 16 out of 150\n",
      "matrix des poids centré\n",
      "[[10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [10.         10.         10.         10.         10.         10.\n",
      "  10.         10.         10.         10.        ]\n",
      " [ 8.92526873  8.92526873  8.92526873  8.92526873  8.92526873  8.92526873\n",
      "   8.92526873  8.92526873  8.92526873  8.92526873]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]\n",
      " [ 5.          5.          5.          5.          5.          5.\n",
      "   5.          5.          5.          5.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 17 out of 150\n"
     ]
    }
   ],
   "source": [
    "spikes = np.zeros((10, len(excitatory_group)))\n",
    "#print(\"spikes avant de partir : \", spikes )\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n",
    "old_spike_counts_i = np.zeros(len(excitatory_group))\n",
    "evolution_moyenne_spike = []\n",
    "evolution_moyenne_matrice_poids = []\n",
    "evolution_moyenne_spike_i = []\n",
    "\n",
    "# Entrainement\n",
    "number_of_epochs = 1\n",
    "\n",
    "for i in range(number_of_epochs):\n",
    "    print('Starting epoch %i' % i)\n",
    "    for j, (sample, label) in enumerate(zip(X_train, y_train)):\n",
    "        # Afficher régulièrement l'état d'avancement\n",
    "        if (j % 1) == 0:\n",
    "            print(\"Running sample %i out of %i\" % (j, len(X_train)))\n",
    "        \n",
    "        #print(\"sample : \", sample)\n",
    "        #print(\"Taux de décharge neurone de poisson avant : \", input_group.rates)\n",
    "\n",
    "        # Configurer le taux d'entrée\n",
    "        input_group.rates = sample / 4 * units.Hz # Completed\n",
    "        #print(\"Taux de décharge neurone de poisson aprés : \", input_group.rates)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Simuler le réseau\n",
    "        net.run(time_per_sample)\n",
    "        \n",
    "        evolution_moyenne_spike.append(np.average(e_monitor.count - old_spike_counts))\n",
    "        evolution_moyenne_spike_i.append(np.average(i_monitor.count - old_spike_counts_i))\n",
    "        \n",
    "\n",
    "        # Enregistrer les décharges\n",
    "        #print(e_monitor.count)\n",
    "        spikes[int(label)] += e_monitor.count - old_spike_counts\n",
    "        #print(\"nouveau spikes : \", spikes)\n",
    "        # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "        old_spike_counts_i = np.copy(i_monitor.count)\n",
    "        \n",
    "        \n",
    "       \n",
    "        weight_matrix = np.zeros([784, NUMBER_NODES_PER_LAYER]) # Completed\n",
    "        weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "        evolution_moyenne_matrice_poids.append(np.average(weight_matrix))\n",
    "        #print(f'Weights avg: {np.average(weight_matrix)}')\n",
    "        #print('-------------- Matrix - 0:10 --------------')\n",
    "        #print(weight_matrix[0:10,0:10])\n",
    "        #print('-------------- Matrix - 385:395 --------------')\n",
    "        #print('input')\n",
    "        #print(input_group.rates[385:395])\n",
    "        print('matrix des poids centré')\n",
    "        print(weight_matrix[385:395,0:10])\n",
    "\n",
    "        # Arrêter l'entrée\n",
    "        input_group.rates = 0 * units.Hz\n",
    "        \n",
    "        # Laisser les variables retourner à leurs valeurs de repos\n",
    "        net.run(resting_time)\n",
    "\n",
    "        # Normaliser les poids\n",
    "        if NORMALIZATION:\n",
    "\n",
    "            weight_matrix = np.zeros([784, NUMBER_NODES_PER_LAYER]) # Completed\n",
    "            weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "            # weight_matrix = weight_matrix/input_synapse.wmax\n",
    "            # colFactors = weight_matrix[0] / col_sums\n",
    "            col_sums = np.sum(weight_matrix, axis=0) # Completed\n",
    "            colFactors = 1 / col_sums # Completed\n",
    "\n",
    "            for k in range(len(excitatory_group)):\n",
    "                weight_matrix[:,k] *= colFactors[k]\n",
    "            input_synapse.w = weight_matrix[input_synapse.i, input_synapse.j]\n",
    "            \n",
    "            \n",
    "            \n",
    "#t = np.linspace(0,len(evolution_moyenne_spike), len(evolution_moyenne_spike))\n",
    "subplot(211)\n",
    "plot(evolution_moyenne_spike, label=\"exitateur\")\n",
    "plot(evolution_moyenne_spike_i,  label=\"inhibiteur\")\n",
    "title(\"Evolution de la moyenne des décharge exitateur\")\n",
    "legend()\n",
    "#print(\"Moyenne de décharge au cours du temps : \",evolution_moyenne_spike )\n",
    "subplot(212)\n",
    "plot(evolution_moyenne_matrice_poids )\n",
    "title(\"Evolution de la moyenne des poids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Commençons par trouver le meilleur neurone pour chaque classe de MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Affichage de spikes : \", spikes)\n",
    "##Solution qui ne fonctionne que si la matrice spikes est homogéne (surment un grand nombre d'entrainement)\n",
    "\n",
    "labeled_neuron_beaucoup = [[],[],[],[],[],[],[],[],[],[]] #liste pour chaque classe des indices des neurones qui ont déchargé le plus pour elle pendnat l'entrainement\n",
    "\n",
    "for i in range(len(excitatory_group)):\n",
    "    labeled_neuron_beaucoup[np.argmax(spikes[:,i])].append(i)\n",
    "    \n",
    "print(\"Test pour voir si on peut utiliser ce labeled_neuron : \\n Affichage du Labeled qui marche si spikes est homogéne : \", labeled_neuron_beaucoup)\n",
    "\n",
    "##SOlution en prenant le neurone qui décharge le plus à chaque fois\n",
    "\n",
    "labeled_neuron = np.argmax(spikes, axis=1)\n",
    "\n",
    "print(labeled_neuron)\n",
    "#for i in range(len(labeled_neurons)):\n",
    "#    print(len(labeled_neurons[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent le réseau entrainé!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déasctiver la plasticité STDP\n",
    "input_synapse.plastic = False\n",
    "\n",
    "num_correct_output = 0\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(X_test, y_test)):\n",
    "    # Afficher régulièrement l'état d'avancement\n",
    "    if (i % 1) == 0:\n",
    "        print(\"Running sample %i out of %i\" % (i, len(X_test)))\n",
    "    \n",
    "    # Configurer le taux d'entrée\n",
    "    # ATTENTION, vous pouvez utiliser un autre type d'encodage\n",
    "    input_group.rates = sample / 4 * units.Hz # Completed\n",
    "    \n",
    "    # Simuler le réseau\n",
    "    net.run(time_per_sample)\n",
    "    \n",
    "    # Calculer le nombre de décharges pour l'échantillon\n",
    "    current_spike_count = e_monitor.count - old_spike_counts\n",
    "    print(\"current_spike_count : \",current_spike_count )\n",
    "    # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "    old_spike_counts = np.copy(e_monitor.count)\n",
    "    \n",
    "    # Prédire la classe de l'échantillon\n",
    "    # Completed\n",
    "    \n",
    "    ##Solution qui ne fonctionne que si la matrice spikes est homogéne (surment un grand nombre d'entrainement)\n",
    "    \n",
    "    #On récupére la moyenne des spikes des neurones correspondant aux classes\n",
    "    #average = np.zeros(10)\n",
    "    #for j in range(10):\n",
    "    #    neurone_interet = np.array([int(current_spike_count[x]) for x in labeled_neurons[j]])\n",
    "    #    if len(neurone_interet) != 0: \n",
    "    #        average[j] = mean(neurone_interet)\n",
    "\n",
    "    #On trouve le label (égal à l'indice de la plus grosse moyenne)\n",
    "    #output_label = np.argmax(average)\n",
    "    \n",
    "    ##Solution utilisant le neurone qui décharge le plus pour un label donné\n",
    "    \n",
    "    spikes_interest = np.array([current_spike_count[x] for x in labeled_neuron])\n",
    "    output_label = np.argmax(spikes_interest)\n",
    "    print(\"pikes_interest : \", spikes_interest)\n",
    "    print(\"output_label : \", output_label)\n",
    "    #output_label = np.where(labeled_neurons == np.argmax(current_spike_count))[0][0]\n",
    "\n",
    "    # Si la prédiction est correcte\n",
    "    if output_label == int(label):\n",
    "        num_correct_output += 1\n",
    "        \n",
    "    # Laisser les variables retourner à leurs valeurs de repos\n",
    "    net.run(resting_time)\n",
    "\n",
    "    \n",
    "print(\"The model accuracy is : %.3f\" % (num_correct_output / len(X_test)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
