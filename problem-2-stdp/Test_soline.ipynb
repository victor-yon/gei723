{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEI723, Université de Sherbrooke, Oct. 2020. Jean Rouat\n",
    "\n",
    "Ce notebook est une adaptation de la classification par STDP de MNIST par Diehl & Cook, créé par I. Balafrej pour l'automne 2019, et adapté par A. El Ferdaoussi pour l'automne 2020.\n",
    "\n",
    "L'article de Diehl & Cook est disponible ici: https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full\n",
    "\n",
    "Le modèle est simplifié un peu et réécrit pour Brian2 et Python 3. Le code est à trous, et les parties à compléter sont indiquées par 'COMPLETER'.\n",
    "\n",
    "ATTENTION: 'exemple donné ici utilise seulement des données d'entrainement et de validation (appelées à tort \"test\").\n",
    "\n",
    "Les équations et certains paramètres des neurones sont fournies.\n",
    "\n",
    "Un exemple d'encodage par fréquence est utilisé (voir la partie \"testons à présent le réseau entrainé'). Vous avez toute liberté d'utiliser un autre type d'encodage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_LIMIT = 200\n",
    "TEST_SIZE = 50\n",
    "NUMBER_NODES_PER_LAYER = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de données MNIST\n",
    "\n",
    "On télécharge l'ensemble de données MNIST directement dans le code. MNIST est disponible à https://www.openml.org/d/554\n",
    "\n",
    "L'argument 'data_home' peut être utilisé pour télécharger MNIST dans un répertoire de votre choix. (Le répertoire par défaut est '~/scikit_learn_data/'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST est constituté de 70k d'images de 28x28 pixels, de chiffres.\n",
    "\n",
    "'X' est le vecteur d'images, et 'y' est le vecteur d'étiquettes (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulation avec toutes les images est assez longue à faire rouler. Utilisons uniquement un sous-ensemble de MNIST pour une simulation plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all[:DATA_LIMIT]\n",
    "y = y_all[:DATA_LIMIT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisons MNIST en ensembles d'entrainement et de test pour entrainer et tester le modèle post-apprentissage.\n",
    "\n",
    "Si on travaille avec l'ensemble au complet, on peut prendre 10k pour le test par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons une image aléatoire de l'ensemble de données pour voir ce à quoi ressemble MNIST.\n",
    "\n",
    "Les images dans MNIST sont des vecteurs. Il faut donc les ré-organiser en matrice 28x28 pour les afficher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(X_train)-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "plt.title(\"Échantillon MNIST avec étiquette %s\" % y_train[index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones Brian2\n",
    "\n",
    "On peut maintenant créer un réseau Brian2. Commençons par définir quelques paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixons le seed aléatoire afin de pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "\n",
    "# Horloge de Brian2\n",
    "defaultclock.dt = 0.5 * units.ms\n",
    "\n",
    "# Cible de génération de code pour Brian2\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "time_per_sample =   0.35 * units.second\n",
    "resting_time = 0.15 * units.second\n",
    "\n",
    "v_rest_e = -65. * units.mV \n",
    "v_rest_i = -60. * units.mV \n",
    "\n",
    "v_reset_e = -65. * units.mV\n",
    "v_reset_i = -45. * units.mV\n",
    "\n",
    "E_equ_e = -100. * units.mV\n",
    "E_equ_i = -85. * units.mV \n",
    "\n",
    "v_thresh_e = -52. * units.mV\n",
    "v_thresh_i = -40. * units.mV\n",
    "\n",
    "refrac_e = 5. * units.ms\n",
    "refrac_i = 2. * units.ms\n",
    "\n",
    "tc_theta = 1e7 * units.ms\n",
    "theta_plus_e = 0.05 * units.mV\n",
    "\n",
    "tc_pre_ee = 20 * units.ms\n",
    "tc_post_1_ee = 20 * units.ms\n",
    "tc_post_2_ee = 40 * units.ms\n",
    "\n",
    "# Taux d'apprentissage\n",
    "nu_ee_pre =  1 # [0, 1]\n",
    "nu_ee_post = 1 # [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons l'entrée au réseau de neurones. L'entrée est un encodeur de type codage par COMPLETER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rates = np.ones([1,784])\n",
    "input_group = PoissonGroup(784, rates = input_rates*Hz) # Groupe de Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons notre modèle de neurone ainsi que nos groupes de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_model = '''\n",
    "    dv/dt = ((v_rest_e - v) + ge(E_equ_e -v) + gi(E_equ_i-v)) / tau  : volt (unless refractory)\n",
    "\n",
    "   \n",
    "    \n",
    "    dge/dt = -ge/(1.0*ms)            : 1\n",
    "    \n",
    "    dgi/dt = -gi/(2.0*ms)            : 1\n",
    "    \n",
    "    tau                              : second (constant, shared)\n",
    "    \n",
    "    dtheta/dt = -theta / (tc_theta)  : volt\n",
    "'''\n",
    "\n",
    "excitatory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_e', \n",
    "    threshold='v > v_thresh_e', reset='v = v_reset_e; theta += theta_plus_e', method='euler')\n",
    "excitatory_group.tau = 100 * units.ms\n",
    "\n",
    "inhibitory_group = NeuronGroup(\n",
    "    N=NUMBER_NODES_PER_LAYER, model=neuron_model, refractory='refrac_i', \n",
    "    threshold='v > v_thresh_i', reset='v = v_reset_i', method='euler')\n",
    "inhibitory_group.tau = 10 * units.ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"M = StateMonitor(excitatory_group, 'v', record=True)\\n\\nrun(350*ms)\\n\\nplot(M.t/ms, M.v[0], label='Neuron 0')\\nplot(M.t/ms, M.v[1], label='Neuron 1')\\nplot(M.t/ms, M.v[2], label='Neuron 2')\\nxlabel('Time (ms)')\\nylabel('v')\\nlegend();\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_model = \"w : 1\"\n",
    "\n",
    "stdp_synapse_model = '''\n",
    "    w : 1\n",
    "\n",
    "    plastic : boolean (shared) # Activer/désactiver la plasticité\n",
    "    \n",
    "    post2before : 1\n",
    "\n",
    "    dpre/dt   =   -pre/(tc_pre_ee) : 1 (event-driven) #trace présynaptique\n",
    "\n",
    "    dpost1/dt  = -post1/(tc_post_1_ee) : 1 (event-driven) #trace post synaptique\n",
    "\n",
    "    dpost2/dt  = -post2/(tc_post_2_ee) : 1 (event-driven)\n",
    "\n",
    "    wmax = 10 : 1\n",
    "\n",
    "    mu = 1 : 1\n",
    "    \n",
    "'''\n",
    "\n",
    "stdp_pre = '''\n",
    "    ge_post += w\n",
    "    \n",
    "    pre += 1\n",
    "    \n",
    "    w = clip(w + (nu_ee_pre * post1), 0, wmax)\n",
    "'''\n",
    "\n",
    "stdp_post = '''\n",
    "    post2before = post2\n",
    "    \n",
    "    w = clip(w + nu_ee_post*(pre-1)*(wmax - w)**mu, 0, wmax) # TODO Check equation\n",
    "    \n",
    "    post1 += -1\n",
    "\n",
    "    '''\n",
    "\n",
    "input_synapse = Synapses(input_group, excitatory_group, model=stdp_synapse_model, on_pre=stdp_pre, on_post=stdp_post, method='euler')\n",
    "input_synapse.connect(True) # Fully connected\n",
    "input_synapse.delay = '10 * ms'\n",
    "input_synapse.plastic = True\n",
    "input_synapse.w = '1'\n",
    "\n",
    "e_i_synapse = Synapses(excitatory_group, inhibitory_group, 'w : 1', on_pre='v_post += w')\n",
    "e_i_synapse.connect(True, p=0.0025)\n",
    "e_i_synapse.w = 'rand()*10.4'\n",
    "\n",
    "i_e_synapse = Synapses(inhibitory_group, excitatory_group,'w : 1', on_pre='v_post -= w')\n",
    "i_e_synapse.connect(True, p=0.9)\n",
    "i_e_synapse.w = 'rand()*17.0'\n",
    "\n",
    "\"\"\"M = StateMonitor(excitatory_group, 'v', record=True)\n",
    "\n",
    "run(350*ms)\n",
    "\n",
    "plot(M.t/ms, M.v[0], label='Neuron 0')\n",
    "plot(M.t/ms, M.v[1], label='Neuron 1')\n",
    "plot(M.t/ms, M.v[2], label='Neuron 2')\n",
    "xlabel('Time (ms)')\n",
    "ylabel('v')\n",
    "legend();\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de synapses a-t-on dans le réseau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169402\n"
     ]
    }
   ],
   "source": [
    "print(len(input_synapse) + len(e_i_synapse) + len(i_e_synapse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons un 'readout' pour notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_monitor = SpikeMonitor(excitatory_group, record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "poissongroup_1 has already been simulated, cannot add it to the network. If you were trying to remove and add an object to temporarily stop it from being run, set its active flag to False instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8578123ee582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m net = Network(input_group, excitatory_group, inhibitory_group, \n\u001b[0m\u001b[0;32m      2\u001b[0m               input_synapse, e_i_synapse, i_e_synapse, e_monitor)\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rneurone\\lib\\site-packages\\brian2\\core\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *objs, **kwds)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m#: Stored state of objects (store/restore)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rneurone\\lib\\site-packages\\brian2\\core\\network.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, *objs)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBrianObject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                     raise RuntimeError('%s has already been simulated, cannot '\n\u001b[0m\u001b[0;32m    476\u001b[0m                                        \u001b[1;34m'add it to the network. If you were '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                                        \u001b[1;34m'trying to remove and add an object to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: poissongroup_1 has already been simulated, cannot add it to the network. If you were trying to remove and add an object to temporarily stop it from being run, set its active flag to False instead."
     ]
    }
   ],
   "source": [
    "net = Network(input_group, excitatory_group, inhibitory_group, \n",
    "              input_synapse, e_i_synapse, i_e_synapse, e_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "Entrainons à présent notre réseau.\n",
    "\n",
    "Créons une matrice 'spikes' pour assigner les étiquettes des classes post-apprentissage. Cette matrice accumulera le décompte de décharges par classe.\n",
    "\n",
    "Notre readout 'e_monitor' est actif tout le long de la simulation avec toutes les images. Donc à chaque nouvelle présentation d'image, on doit soustraire l'ancien décompte de décharges. On utilisera le vecteur 'old_spike_counts' pour le faire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Running sample 0 out of 650\n",
      "Running sample 1 out of 650\n",
      "Running sample 2 out of 650\n",
      "Running sample 3 out of 650\n",
      "Running sample 4 out of 650\n",
      "Running sample 5 out of 650\n",
      "Running sample 6 out of 650\n",
      "Running sample 7 out of 650\n",
      "Running sample 8 out of 650\n",
      "Running sample 9 out of 650\n",
      "Running sample 10 out of 650\n",
      "Running sample 11 out of 650\n",
      "Running sample 12 out of 650\n",
      "Running sample 13 out of 650\n",
      "Running sample 14 out of 650\n",
      "Running sample 15 out of 650\n",
      "Running sample 16 out of 650\n",
      "Running sample 17 out of 650\n",
      "Running sample 18 out of 650\n",
      "Running sample 19 out of 650\n",
      "Running sample 20 out of 650\n",
      "Running sample 21 out of 650\n",
      "Running sample 22 out of 650\n",
      "Running sample 23 out of 650\n",
      "Running sample 24 out of 650\n",
      "Running sample 25 out of 650\n",
      "Running sample 26 out of 650\n",
      "Running sample 27 out of 650\n",
      "Running sample 28 out of 650\n",
      "Running sample 29 out of 650\n",
      "Running sample 30 out of 650\n",
      "Running sample 31 out of 650\n",
      "Running sample 32 out of 650\n",
      "Running sample 33 out of 650\n",
      "Running sample 34 out of 650\n",
      "Running sample 35 out of 650\n",
      "Running sample 36 out of 650\n",
      "Running sample 37 out of 650\n",
      "Running sample 38 out of 650\n",
      "Running sample 39 out of 650\n",
      "Running sample 40 out of 650\n",
      "Running sample 41 out of 650\n",
      "Running sample 42 out of 650\n",
      "Running sample 43 out of 650\n",
      "Running sample 44 out of 650\n",
      "Running sample 45 out of 650\n",
      "Running sample 46 out of 650\n",
      "Running sample 47 out of 650\n",
      "Running sample 48 out of 650\n",
      "Running sample 49 out of 650\n",
      "Running sample 50 out of 650\n",
      "Running sample 51 out of 650\n",
      "Running sample 52 out of 650\n",
      "Running sample 53 out of 650\n",
      "Running sample 54 out of 650\n",
      "Running sample 55 out of 650\n",
      "Running sample 56 out of 650\n",
      "Running sample 57 out of 650\n",
      "Running sample 58 out of 650\n",
      "Running sample 59 out of 650\n",
      "Running sample 60 out of 650\n",
      "Running sample 61 out of 650\n",
      "Running sample 62 out of 650\n",
      "Running sample 63 out of 650\n",
      "Running sample 64 out of 650\n",
      "Running sample 65 out of 650\n",
      "Running sample 66 out of 650\n",
      "Running sample 67 out of 650\n",
      "Running sample 68 out of 650\n",
      "Running sample 69 out of 650\n",
      "Running sample 70 out of 650\n",
      "Running sample 71 out of 650\n",
      "Running sample 72 out of 650\n",
      "Running sample 73 out of 650\n",
      "Running sample 74 out of 650\n",
      "Running sample 75 out of 650\n",
      "Running sample 76 out of 650\n",
      "Running sample 77 out of 650\n",
      "Running sample 78 out of 650\n",
      "Running sample 79 out of 650\n",
      "Running sample 80 out of 650\n",
      "Running sample 81 out of 650\n",
      "Running sample 82 out of 650\n",
      "Running sample 83 out of 650\n",
      "Running sample 84 out of 650\n",
      "Running sample 85 out of 650\n",
      "Running sample 86 out of 650\n",
      "Running sample 87 out of 650\n",
      "Running sample 88 out of 650\n",
      "Running sample 89 out of 650\n",
      "Running sample 90 out of 650\n",
      "Running sample 91 out of 650\n",
      "Running sample 92 out of 650\n",
      "Running sample 93 out of 650\n",
      "Running sample 94 out of 650\n",
      "Running sample 95 out of 650\n",
      "Running sample 96 out of 650\n",
      "Running sample 97 out of 650\n",
      "Running sample 98 out of 650\n",
      "Running sample 99 out of 650\n",
      "Running sample 100 out of 650\n",
      "Running sample 101 out of 650\n",
      "Running sample 102 out of 650\n",
      "Running sample 103 out of 650\n",
      "Running sample 104 out of 650\n",
      "Running sample 105 out of 650\n",
      "Running sample 106 out of 650\n",
      "Running sample 107 out of 650\n",
      "Running sample 108 out of 650\n",
      "Running sample 109 out of 650\n",
      "Running sample 110 out of 650\n",
      "Running sample 111 out of 650\n",
      "Running sample 112 out of 650\n",
      "Running sample 113 out of 650\n",
      "Running sample 114 out of 650\n",
      "Running sample 115 out of 650\n",
      "Running sample 116 out of 650\n",
      "Running sample 117 out of 650\n",
      "Running sample 118 out of 650\n",
      "Running sample 119 out of 650\n",
      "Running sample 120 out of 650\n",
      "Running sample 121 out of 650\n",
      "Running sample 122 out of 650\n",
      "Running sample 123 out of 650\n",
      "Running sample 124 out of 650\n",
      "Running sample 125 out of 650\n",
      "Running sample 126 out of 650\n",
      "Running sample 127 out of 650\n",
      "Running sample 128 out of 650\n",
      "Running sample 129 out of 650\n",
      "Running sample 130 out of 650\n",
      "Running sample 131 out of 650\n",
      "Running sample 132 out of 650\n",
      "Running sample 133 out of 650\n",
      "Running sample 134 out of 650\n",
      "Running sample 135 out of 650\n",
      "Running sample 136 out of 650\n",
      "Running sample 137 out of 650\n",
      "Running sample 138 out of 650\n",
      "Running sample 139 out of 650\n",
      "Running sample 140 out of 650\n",
      "Running sample 141 out of 650\n",
      "Running sample 142 out of 650\n",
      "Running sample 143 out of 650\n",
      "Running sample 144 out of 650\n",
      "Running sample 145 out of 650\n",
      "Running sample 146 out of 650\n",
      "Running sample 147 out of 650\n",
      "Running sample 148 out of 650\n",
      "Running sample 149 out of 650\n",
      "Running sample 150 out of 650\n",
      "Running sample 151 out of 650\n",
      "Running sample 152 out of 650\n",
      "Running sample 153 out of 650\n",
      "Running sample 154 out of 650\n",
      "Running sample 155 out of 650\n",
      "Running sample 156 out of 650\n",
      "Running sample 157 out of 650\n",
      "Running sample 158 out of 650\n",
      "Running sample 159 out of 650\n",
      "Running sample 160 out of 650\n",
      "Running sample 161 out of 650\n",
      "Running sample 162 out of 650\n",
      "Running sample 163 out of 650\n",
      "Running sample 164 out of 650\n",
      "Running sample 165 out of 650\n",
      "Running sample 166 out of 650\n",
      "Running sample 167 out of 650\n",
      "Running sample 168 out of 650\n",
      "Running sample 169 out of 650\n",
      "Running sample 170 out of 650\n",
      "Running sample 171 out of 650\n",
      "Running sample 172 out of 650\n",
      "Running sample 173 out of 650\n",
      "Running sample 174 out of 650\n",
      "Running sample 175 out of 650\n",
      "Running sample 176 out of 650\n",
      "Running sample 177 out of 650\n",
      "Running sample 178 out of 650\n",
      "Running sample 179 out of 650\n",
      "Running sample 180 out of 650\n",
      "Running sample 181 out of 650\n",
      "Running sample 182 out of 650\n",
      "Running sample 183 out of 650\n",
      "Running sample 184 out of 650\n",
      "Running sample 185 out of 650\n",
      "Running sample 186 out of 650\n",
      "Running sample 187 out of 650\n",
      "Running sample 188 out of 650\n",
      "Running sample 189 out of 650\n",
      "Running sample 190 out of 650\n",
      "Running sample 191 out of 650\n",
      "Running sample 192 out of 650\n",
      "Running sample 193 out of 650\n",
      "Running sample 194 out of 650\n",
      "Running sample 195 out of 650\n",
      "Running sample 196 out of 650\n",
      "Running sample 197 out of 650\n",
      "Running sample 198 out of 650\n",
      "Running sample 199 out of 650\n",
      "Running sample 200 out of 650\n",
      "Running sample 201 out of 650\n",
      "Running sample 202 out of 650\n",
      "Running sample 203 out of 650\n",
      "Running sample 204 out of 650\n",
      "Running sample 205 out of 650\n",
      "Running sample 206 out of 650\n",
      "Running sample 207 out of 650\n",
      "Running sample 208 out of 650\n",
      "Running sample 209 out of 650\n",
      "Running sample 210 out of 650\n",
      "Running sample 211 out of 650\n",
      "Running sample 212 out of 650\n",
      "Running sample 213 out of 650\n",
      "Running sample 214 out of 650\n",
      "Running sample 215 out of 650\n",
      "Running sample 216 out of 650\n",
      "Running sample 217 out of 650\n",
      "Running sample 218 out of 650\n",
      "Running sample 219 out of 650\n",
      "Running sample 220 out of 650\n",
      "Running sample 221 out of 650\n",
      "Running sample 222 out of 650\n",
      "Running sample 223 out of 650\n",
      "Running sample 224 out of 650\n",
      "Running sample 225 out of 650\n",
      "Running sample 226 out of 650\n",
      "Running sample 227 out of 650\n",
      "Running sample 228 out of 650\n",
      "Running sample 229 out of 650\n",
      "Running sample 230 out of 650\n",
      "Running sample 231 out of 650\n",
      "Running sample 232 out of 650\n",
      "Running sample 233 out of 650\n",
      "Running sample 234 out of 650\n",
      "Running sample 235 out of 650\n",
      "Running sample 236 out of 650\n",
      "Running sample 237 out of 650\n",
      "Running sample 238 out of 650\n",
      "Running sample 239 out of 650\n",
      "Running sample 240 out of 650\n",
      "Running sample 241 out of 650\n",
      "Running sample 242 out of 650\n",
      "Running sample 243 out of 650\n",
      "Running sample 244 out of 650\n",
      "Running sample 245 out of 650\n",
      "Running sample 246 out of 650\n",
      "Running sample 247 out of 650\n",
      "Running sample 248 out of 650\n",
      "Running sample 249 out of 650\n",
      "Running sample 250 out of 650\n",
      "Running sample 251 out of 650\n",
      "Running sample 252 out of 650\n",
      "Running sample 253 out of 650\n",
      "Running sample 254 out of 650\n",
      "Running sample 255 out of 650\n",
      "Running sample 256 out of 650\n",
      "Running sample 257 out of 650\n",
      "Running sample 258 out of 650\n",
      "Running sample 259 out of 650\n",
      "Running sample 260 out of 650\n",
      "Running sample 261 out of 650\n",
      "Running sample 262 out of 650\n",
      "Running sample 263 out of 650\n",
      "Running sample 264 out of 650\n",
      "Running sample 265 out of 650\n",
      "Running sample 266 out of 650\n",
      "Running sample 267 out of 650\n",
      "Running sample 268 out of 650\n",
      "Running sample 269 out of 650\n",
      "Running sample 270 out of 650\n",
      "Running sample 271 out of 650\n",
      "Running sample 272 out of 650\n",
      "Running sample 273 out of 650\n",
      "Running sample 274 out of 650\n",
      "Running sample 275 out of 650\n",
      "Running sample 276 out of 650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 277 out of 650\n",
      "Running sample 278 out of 650\n",
      "Running sample 279 out of 650\n",
      "Running sample 280 out of 650\n",
      "Running sample 281 out of 650\n",
      "Running sample 282 out of 650\n",
      "Running sample 283 out of 650\n",
      "Running sample 284 out of 650\n",
      "Running sample 285 out of 650\n",
      "Running sample 286 out of 650\n",
      "Running sample 287 out of 650\n",
      "Running sample 288 out of 650\n",
      "Running sample 289 out of 650\n",
      "Running sample 290 out of 650\n",
      "Running sample 291 out of 650\n",
      "Running sample 292 out of 650\n",
      "Running sample 293 out of 650\n",
      "Running sample 294 out of 650\n",
      "Running sample 295 out of 650\n",
      "Running sample 296 out of 650\n",
      "Running sample 297 out of 650\n",
      "Running sample 298 out of 650\n",
      "Running sample 299 out of 650\n",
      "Running sample 300 out of 650\n",
      "Running sample 301 out of 650\n",
      "Running sample 302 out of 650\n",
      "Running sample 303 out of 650\n",
      "Running sample 304 out of 650\n",
      "Running sample 305 out of 650\n",
      "Running sample 306 out of 650\n",
      "Running sample 307 out of 650\n",
      "Running sample 308 out of 650\n",
      "Running sample 309 out of 650\n",
      "Running sample 310 out of 650\n",
      "Running sample 311 out of 650\n",
      "Running sample 312 out of 650\n",
      "Running sample 313 out of 650\n",
      "Running sample 314 out of 650\n",
      "Running sample 315 out of 650\n",
      "Running sample 316 out of 650\n",
      "Running sample 317 out of 650\n",
      "Running sample 318 out of 650\n",
      "Running sample 319 out of 650\n",
      "Running sample 320 out of 650\n",
      "Running sample 321 out of 650\n",
      "Running sample 322 out of 650\n",
      "Running sample 323 out of 650\n",
      "Running sample 324 out of 650\n",
      "Running sample 325 out of 650\n",
      "Running sample 326 out of 650\n",
      "Running sample 327 out of 650\n",
      "Running sample 328 out of 650\n",
      "Running sample 329 out of 650\n",
      "Running sample 330 out of 650\n",
      "Running sample 331 out of 650\n",
      "Running sample 332 out of 650\n",
      "Running sample 333 out of 650\n",
      "Running sample 334 out of 650\n",
      "Running sample 335 out of 650\n",
      "Running sample 336 out of 650\n",
      "Running sample 337 out of 650\n",
      "Running sample 338 out of 650\n",
      "Running sample 339 out of 650\n",
      "Running sample 340 out of 650\n",
      "Running sample 341 out of 650\n",
      "Running sample 342 out of 650\n",
      "Running sample 343 out of 650\n",
      "Running sample 344 out of 650\n",
      "Running sample 345 out of 650\n",
      "Running sample 346 out of 650\n",
      "Running sample 347 out of 650\n",
      "Running sample 348 out of 650\n",
      "Running sample 349 out of 650\n",
      "Running sample 350 out of 650\n",
      "Running sample 351 out of 650\n",
      "Running sample 352 out of 650\n",
      "Running sample 353 out of 650\n",
      "Running sample 354 out of 650\n",
      "Running sample 355 out of 650\n",
      "Running sample 356 out of 650\n",
      "Running sample 357 out of 650\n",
      "Running sample 358 out of 650\n",
      "Running sample 359 out of 650\n",
      "Running sample 360 out of 650\n",
      "Running sample 361 out of 650\n",
      "Running sample 362 out of 650\n",
      "Running sample 363 out of 650\n",
      "Running sample 364 out of 650\n",
      "Running sample 365 out of 650\n",
      "Running sample 366 out of 650\n",
      "Running sample 367 out of 650\n",
      "Running sample 368 out of 650\n",
      "Running sample 369 out of 650\n",
      "Running sample 370 out of 650\n",
      "Running sample 371 out of 650\n",
      "Running sample 372 out of 650\n",
      "Running sample 373 out of 650\n",
      "Running sample 374 out of 650\n",
      "Running sample 375 out of 650\n",
      "Running sample 376 out of 650\n",
      "Running sample 377 out of 650\n",
      "Running sample 378 out of 650\n",
      "Running sample 379 out of 650\n",
      "Running sample 380 out of 650\n",
      "Running sample 381 out of 650\n",
      "Running sample 382 out of 650\n",
      "Running sample 383 out of 650\n",
      "Running sample 384 out of 650\n",
      "Running sample 385 out of 650\n",
      "Running sample 386 out of 650\n",
      "Running sample 387 out of 650\n",
      "Running sample 388 out of 650\n",
      "Running sample 389 out of 650\n",
      "Running sample 390 out of 650\n",
      "Running sample 391 out of 650\n",
      "Running sample 392 out of 650\n",
      "Running sample 393 out of 650\n",
      "Running sample 394 out of 650\n",
      "Running sample 395 out of 650\n",
      "Running sample 396 out of 650\n",
      "Running sample 397 out of 650\n",
      "Running sample 398 out of 650\n",
      "Running sample 399 out of 650\n",
      "Running sample 400 out of 650\n",
      "Running sample 401 out of 650\n",
      "Running sample 402 out of 650\n",
      "Running sample 403 out of 650\n",
      "Running sample 404 out of 650\n",
      "Running sample 405 out of 650\n",
      "Running sample 406 out of 650\n",
      "Running sample 407 out of 650\n",
      "Running sample 408 out of 650\n",
      "Running sample 409 out of 650\n",
      "Running sample 410 out of 650\n",
      "Running sample 411 out of 650\n",
      "Running sample 412 out of 650\n",
      "Running sample 413 out of 650\n",
      "Running sample 414 out of 650\n",
      "Running sample 415 out of 650\n",
      "Running sample 416 out of 650\n",
      "Running sample 417 out of 650\n",
      "Running sample 418 out of 650\n",
      "Running sample 419 out of 650\n",
      "Running sample 420 out of 650\n",
      "Running sample 421 out of 650\n",
      "Running sample 422 out of 650\n",
      "Running sample 423 out of 650\n",
      "Running sample 424 out of 650\n",
      "Running sample 425 out of 650\n",
      "Running sample 426 out of 650\n",
      "Running sample 427 out of 650\n",
      "Running sample 428 out of 650\n",
      "Running sample 429 out of 650\n",
      "Running sample 430 out of 650\n",
      "Running sample 431 out of 650\n",
      "Running sample 432 out of 650\n",
      "Running sample 433 out of 650\n",
      "Running sample 434 out of 650\n",
      "Running sample 435 out of 650\n",
      "Running sample 436 out of 650\n",
      "Running sample 437 out of 650\n",
      "Running sample 438 out of 650\n",
      "Running sample 439 out of 650\n",
      "Running sample 440 out of 650\n",
      "Running sample 441 out of 650\n",
      "Running sample 442 out of 650\n",
      "Running sample 443 out of 650\n",
      "Running sample 444 out of 650\n",
      "Running sample 445 out of 650\n",
      "Running sample 446 out of 650\n",
      "Running sample 447 out of 650\n",
      "Running sample 448 out of 650\n",
      "Running sample 449 out of 650\n",
      "Running sample 450 out of 650\n",
      "Running sample 451 out of 650\n",
      "Running sample 452 out of 650\n",
      "Running sample 453 out of 650\n",
      "Running sample 454 out of 650\n",
      "Running sample 455 out of 650\n",
      "Running sample 456 out of 650\n",
      "Running sample 457 out of 650\n",
      "Running sample 458 out of 650\n",
      "Running sample 459 out of 650\n",
      "Running sample 460 out of 650\n",
      "Running sample 461 out of 650\n",
      "Running sample 462 out of 650\n",
      "Running sample 463 out of 650\n",
      "Running sample 464 out of 650\n",
      "Running sample 465 out of 650\n",
      "Running sample 466 out of 650\n",
      "Running sample 467 out of 650\n",
      "Running sample 468 out of 650\n",
      "Running sample 469 out of 650\n",
      "Running sample 470 out of 650\n",
      "Running sample 471 out of 650\n",
      "Running sample 472 out of 650\n",
      "Running sample 473 out of 650\n",
      "Running sample 474 out of 650\n",
      "Running sample 475 out of 650\n",
      "Running sample 476 out of 650\n",
      "Running sample 477 out of 650\n",
      "Running sample 478 out of 650\n",
      "Running sample 479 out of 650\n",
      "Running sample 480 out of 650\n",
      "Running sample 481 out of 650\n",
      "Running sample 482 out of 650\n",
      "Running sample 483 out of 650\n",
      "Running sample 484 out of 650\n",
      "Running sample 485 out of 650\n",
      "Running sample 486 out of 650\n",
      "Running sample 487 out of 650\n",
      "Running sample 488 out of 650\n",
      "Running sample 489 out of 650\n",
      "Running sample 490 out of 650\n",
      "Running sample 491 out of 650\n",
      "Running sample 492 out of 650\n",
      "Running sample 493 out of 650\n",
      "Running sample 494 out of 650\n",
      "Running sample 495 out of 650\n",
      "Running sample 496 out of 650\n",
      "Running sample 497 out of 650\n",
      "Running sample 498 out of 650\n",
      "Running sample 499 out of 650\n",
      "Running sample 500 out of 650\n",
      "Running sample 501 out of 650\n",
      "Running sample 502 out of 650\n",
      "Running sample 503 out of 650\n",
      "Running sample 504 out of 650\n",
      "Running sample 505 out of 650\n",
      "Running sample 506 out of 650\n",
      "Running sample 507 out of 650\n",
      "Running sample 508 out of 650\n",
      "Running sample 509 out of 650\n",
      "Running sample 510 out of 650\n",
      "Running sample 511 out of 650\n",
      "Running sample 512 out of 650\n",
      "Running sample 513 out of 650\n",
      "Running sample 514 out of 650\n",
      "Running sample 515 out of 650\n",
      "Running sample 516 out of 650\n",
      "Running sample 517 out of 650\n",
      "Running sample 518 out of 650\n",
      "Running sample 519 out of 650\n",
      "Running sample 520 out of 650\n",
      "Running sample 521 out of 650\n",
      "Running sample 522 out of 650\n",
      "Running sample 523 out of 650\n",
      "Running sample 524 out of 650\n",
      "Running sample 525 out of 650\n",
      "Running sample 526 out of 650\n",
      "Running sample 527 out of 650\n",
      "Running sample 528 out of 650\n",
      "Running sample 529 out of 650\n",
      "Running sample 530 out of 650\n",
      "Running sample 531 out of 650\n",
      "Running sample 532 out of 650\n",
      "Running sample 533 out of 650\n",
      "Running sample 534 out of 650\n",
      "Running sample 535 out of 650\n",
      "Running sample 536 out of 650\n",
      "Running sample 537 out of 650\n",
      "Running sample 538 out of 650\n",
      "Running sample 539 out of 650\n",
      "Running sample 540 out of 650\n",
      "Running sample 541 out of 650\n",
      "Running sample 542 out of 650\n",
      "Running sample 543 out of 650\n",
      "Running sample 544 out of 650\n",
      "Running sample 545 out of 650\n",
      "Running sample 546 out of 650\n",
      "Running sample 547 out of 650\n",
      "Running sample 548 out of 650\n",
      "Running sample 549 out of 650\n",
      "Running sample 550 out of 650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 551 out of 650\n",
      "Running sample 552 out of 650\n",
      "Running sample 553 out of 650\n",
      "Running sample 554 out of 650\n",
      "Running sample 555 out of 650\n",
      "Running sample 556 out of 650\n",
      "Running sample 557 out of 650\n",
      "Running sample 558 out of 650\n",
      "Running sample 559 out of 650\n",
      "Running sample 560 out of 650\n",
      "Running sample 561 out of 650\n",
      "Running sample 562 out of 650\n",
      "Running sample 563 out of 650\n",
      "Running sample 564 out of 650\n",
      "Running sample 565 out of 650\n",
      "Running sample 566 out of 650\n",
      "Running sample 567 out of 650\n",
      "Running sample 568 out of 650\n",
      "Running sample 569 out of 650\n",
      "Running sample 570 out of 650\n",
      "Running sample 571 out of 650\n",
      "Running sample 572 out of 650\n",
      "Running sample 573 out of 650\n",
      "Running sample 574 out of 650\n",
      "Running sample 575 out of 650\n",
      "Running sample 576 out of 650\n",
      "Running sample 577 out of 650\n",
      "Running sample 578 out of 650\n",
      "Running sample 579 out of 650\n",
      "Running sample 580 out of 650\n",
      "Running sample 581 out of 650\n",
      "Running sample 582 out of 650\n",
      "Running sample 583 out of 650\n",
      "Running sample 584 out of 650\n",
      "Running sample 585 out of 650\n",
      "Running sample 586 out of 650\n",
      "Running sample 587 out of 650\n",
      "Running sample 588 out of 650\n",
      "Running sample 589 out of 650\n",
      "Running sample 590 out of 650\n",
      "Running sample 591 out of 650\n",
      "Running sample 592 out of 650\n",
      "Running sample 593 out of 650\n",
      "Running sample 594 out of 650\n",
      "Running sample 595 out of 650\n",
      "Running sample 596 out of 650\n",
      "Running sample 597 out of 650\n",
      "Running sample 598 out of 650\n",
      "Running sample 599 out of 650\n",
      "Running sample 600 out of 650\n",
      "Running sample 601 out of 650\n",
      "Running sample 602 out of 650\n",
      "Running sample 603 out of 650\n",
      "Running sample 604 out of 650\n",
      "Running sample 605 out of 650\n",
      "Running sample 606 out of 650\n",
      "Running sample 607 out of 650\n",
      "Running sample 608 out of 650\n",
      "Running sample 609 out of 650\n",
      "Running sample 610 out of 650\n",
      "Running sample 611 out of 650\n",
      "Running sample 612 out of 650\n",
      "Running sample 613 out of 650\n",
      "Running sample 614 out of 650\n",
      "Running sample 615 out of 650\n",
      "Running sample 616 out of 650\n",
      "Running sample 617 out of 650\n",
      "Running sample 618 out of 650\n",
      "Running sample 619 out of 650\n",
      "Running sample 620 out of 650\n",
      "Running sample 621 out of 650\n",
      "Running sample 622 out of 650\n",
      "Running sample 623 out of 650\n",
      "Running sample 624 out of 650\n",
      "Running sample 625 out of 650\n",
      "Running sample 626 out of 650\n",
      "Running sample 627 out of 650\n",
      "Running sample 628 out of 650\n",
      "Running sample 629 out of 650\n",
      "Running sample 630 out of 650\n",
      "Running sample 631 out of 650\n",
      "Running sample 632 out of 650\n",
      "Running sample 633 out of 650\n",
      "Running sample 634 out of 650\n",
      "Running sample 635 out of 650\n",
      "Running sample 636 out of 650\n",
      "Running sample 637 out of 650\n",
      "Running sample 638 out of 650\n",
      "Running sample 639 out of 650\n",
      "Running sample 640 out of 650\n",
      "Running sample 641 out of 650\n",
      "Running sample 642 out of 650\n",
      "Running sample 643 out of 650\n",
      "Running sample 644 out of 650\n",
      "Running sample 645 out of 650\n",
      "Running sample 646 out of 650\n",
      "Running sample 647 out of 650\n",
      "Running sample 648 out of 650\n",
      "Running sample 649 out of 650\n"
     ]
    }
   ],
   "source": [
    "spikes = np.zeros((10, len(excitatory_group)))\n",
    "old_spike_counts = np.zeros(len(excitatory_group))\n",
    "\n",
    "# Entrainement\n",
    "number_of_epochs = 1\n",
    "\n",
    "for i in range(number_of_epochs):\n",
    "    print('Starting epoch %i' % i)\n",
    "    for j, (sample, label) in enumerate(zip(X_train, y_train)):\n",
    "        # Afficher régulièrement l'état d'avancement\n",
    "        if (j % 1) == 0:\n",
    "            print(\"Running sample %i out of %i\" % (j, len(X_train)))\n",
    "\n",
    "        # Configurer le taux d'entrée\n",
    "        input_group.rates = sample / 4 * units.Hz\n",
    "\n",
    "        # Simuler le réseau\n",
    "        net.run(time_per_sample)\n",
    "\n",
    "        # Enregistrer les décharges\n",
    "        spikes[int(label)] += e_monitor.count - old_spike_counts\n",
    "        # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "        old_spike_counts = np.copy(e_monitor.count)\n",
    "        \n",
    "        # Arrêter l'entrée\n",
    "        input_group.rates = 0 * units.Hz\n",
    "        \n",
    "        # Laisser les variables retourner à leurs valeurs de repos\n",
    "        net.run(resting_time)\n",
    "        \n",
    "        # Normaliser les poids\n",
    "        weight_matrix = np.zeros([784, 784])\n",
    "        weight_matrix[input_synapse.i, input_synapse.j] = input_synapse.w\n",
    "        # weight_matrix = weight_matrix/input_synapse.wmax\n",
    "        col_sums = np.sum(weight_matrix, axis=0)\n",
    "        # colFactors = weight_matrix[0] / col_sums\n",
    "        colFactors = 1 / col_sums\n",
    "\n",
    "        for k in range(len(excitatory_group)):\n",
    "            weight_matrix[:,k] *= colFactors[k]\n",
    "        input_synapse.w = weight_matrix[input_synapse.i, input_synapse.j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Commençons par trouver le meilleur neurone pour chaque classe de MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_neurons = np.argmax(spikes, axis=1)\n",
    "\n",
    "labeled_neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent le réseau entrainé!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample 0 out of 50\n",
      "Running sample 10 out of 50\n",
      "Running sample 20 out of 50\n",
      "Running sample 30 out of 50\n",
      "Running sample 40 out of 50\n",
      "The model accuracy is : 0.120\n"
     ]
    }
   ],
   "source": [
    "# Déasctiver la plasticité STDP\n",
    "input_synapse.plastic = False\n",
    "\n",
    "num_correct_output = 0\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(X_test, y_test)):\n",
    "    # Afficher régulièrement l'état d'avancement\n",
    "    if (i % 10) == 0:\n",
    "        print(\"Running sample %i out of %i\" % (i, len(X_test)))\n",
    "    \n",
    "    # Configurer le taux d'entrée\n",
    "    # ATTENTION, vous pouvez utiliser un autre type d'encodage\n",
    "    input_group.rates = sample / 4 * units.Hz\n",
    "    \n",
    "    # Simuler le réseau\n",
    "    net.run(time_per_sample)\n",
    "    \n",
    "    # Calculer le nombre de décharges pour l'échantillon\n",
    "    current_spike_count = e_monitor.count - old_spike_counts\n",
    "    # Gardons une copie du décompte de décharges pour pouvoir calculer le prochain\n",
    "    old_spike_counts = np.copy(e_monitor.count)\n",
    "    \n",
    "    # Prédire la classe de l'échantillon\n",
    "    #On récupére le nb de spike des neurones correspondant au labeled\n",
    "    nb_spike_interet = np.array([current_spike_count[x] for x in labeled_neurons ])\n",
    "    #On trouve le label (égal à l'indice)\n",
    "    output_label = np.argmax(nb_spike_interet)\n",
    "    #output_label = np.where(labeled_neurons == np.argmax(current_spike_count))[0][0]\n",
    "    \n",
    "    # Si la prédiction est correcte\n",
    "    if output_label == int(label):\n",
    "        num_correct_output += 1\n",
    "        \n",
    "    # Laisser les variables retourner à leurs valeurs de repos\n",
    "    net.run(resting_time)\n",
    "\n",
    "    \n",
    "print(\"The model accuracy is : %.3f\" % (num_correct_output / len(X_test)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
